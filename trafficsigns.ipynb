{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfd5f7f-5e81-43f7-ae43-eece598f012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'german-traffic-signs' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://bitbucket.org/jadslim/german-traffic-signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7804063e-2730-48f1-8762-61c19c2f3c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 860B-D5C8\n",
      "\n",
      " Directory of C:\\Users\\YASEEN ALI GAZI\\OneDrive\\Desktop\\Project Self Driving Car\\german-traffic-signs\n",
      "\n",
      "22-04-2025  03:09    <DIR>          .\n",
      "22-04-2025  03:56    <DIR>          ..\n",
      "22-04-2025  03:09             1,043 signnames.csv\n",
      "22-04-2025  03:09        38,888,118 test.p\n",
      "22-04-2025  03:09       107,146,452 train.p\n",
      "22-04-2025  03:09        13,578,712 valid.p\n",
      "               4 File(s)    159,614,325 bytes\n",
      "               2 Dir(s)  58,534,019,072 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir german-traffic-signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b963db98-8363-496e-9a91-d36d05520db2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing defs: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\keras\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\keras\\api\\__init__.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\keras\\api\\saving\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_editor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasFileEditor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CustomObjectScope\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     CustomObjectScope \u001b[38;5;28;01mas\u001b[39;00m custom_object_scope,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\keras\\src\\saving\\file_editor.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\h5py\\__init__.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mhdf5_version_tuple \u001b[38;5;241m!=\u001b[39m version\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple:\n\u001b[0;32m     36\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[0;32m     40\u001b[0m     ))\n",
      "File \u001b[1;32m~\\.conda\\envs\\aiml_env\\lib\\site-packages\\h5py\\version.py:15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Versioning module for h5py.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m h5 \u001b[38;5;28;01mas\u001b[39;00m _h5\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n",
      "File \u001b[1;32mh5py\\\\h5.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing defs: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import random\n",
    "import pickle\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e737be-5cb0-40e4-b8bb-6cf2f7ff2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b914af6b-9eb6-4770-bc3a-177f018976ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#TODO: Implement load the data here.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgerman-traffic-signs/train.p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgerman-traffic-signs/valid.p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "#TODO: Implement load the data here.\n",
    "with open('german-traffic-signs/train.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('german-traffic-signs/valid.p', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "# TODO: Load test data\n",
    "with open('german-traffic-signs/test.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0202f7f8-168d-485f-8316-786603706b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split out features and labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Split out features and labels\n",
    "X_train, y_train = train_data['features'], train_data['labels']\n",
    "X_val, y_val = val_data['features'], val_data['labels']\n",
    "X_test, y_test = test_data['features'], test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bff3fa-0b28-4724-a3dd-7130f2378ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#already 4 dimensional\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12462db-97bb-4af1-9256-6f946ae99f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP: Do not change the tests below. Your implementation should pass these tests. \n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\n",
    "assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\n",
    "assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels.\"\n",
    "assert(X_test.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ab7c7-8f5a-49c6-87d8-91fa7b1fad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('german-traffic-signs/signnames.csv')\n",
    "  \n",
    "num_of_samples=[]\n",
    "\n",
    "cols = 5\n",
    "num_classes = 43\n",
    "\n",
    "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(cols):\n",
    "    for j, row in data.iterrows():\n",
    "        x_selected = X_train[y_train == j]\n",
    "        axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))\n",
    "        axs[j][i].axis(\"off\")\n",
    "        if i == 2:\n",
    "          axs[j][i].set_title(str(j) + \" - \" + row[\"SignName\"])\n",
    "          num_of_samples.append(len(x_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f6b6f0-849c-40db-8565-04a95d7f2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_of_samples)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(0, num_classes), num_of_samples)\n",
    "plt.title(\"Distribution of the train dataset\")\n",
    "plt.xlabel(\"Class number\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a91911-7056-4929-9721-4d1f53fa19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1000])\n",
    "plt.axis(\"off\")\n",
    "print(X_train[1000].shape)\n",
    "print(y_train[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18c1a2-6022-462a-8aff-0a06d6d9e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "img = grayscale(X_train[1000])\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127349c7-cdce-4eaf-95cc-6b5a663a69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "img = equalize(img)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b537c16-f1fe-44fd-a31a-5fbafeddd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "  \n",
    "X_train = np.array(list(map(preprocess, X_train)))\n",
    "X_test = np.array(list(map(preprocess, X_test)))\n",
    "X_val = np.array(list(map(preprocess, X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b77f0c-e1a8-46ee-8d2d-cc91ac21aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[random.randint(0, len(X_train) - 1)])\n",
    "plt.axis('off')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8034e-bcc9-4ec1-b707-0dbe5878c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(34799, 32, 32, 1)\n",
    "X_test = X_test.reshape(12630, 32, 32, 1)\n",
    "X_val = X_val.reshape(4410, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee88c05-227a-400b-aace-a23b5caea447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, shear_range=0.1, rotation_range=10)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64d11d-e480-4319-80a0-b7c24ff1215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_batch, y_batch in\n",
    "\n",
    "batches = datagen.flow(X_train, y_train, batch_size = 15)\n",
    "X_batch, y_batch = next(batches)\n",
    "\n",
    "fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(15):\n",
    "    axs[i].imshow(X_batch[i].reshape(32, 32))\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "print(X_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01390ec-0482-4578-9ad1-acadf482188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)\n",
    "y_val = to_categorical(y_val, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f8e63-293d-45e3-98b9-5b80c69b6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "def modified_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\n",
    "  model.add(Conv2D(60, (5, 5), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "  model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(500, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(43, activation='softmax'))\n",
    "  \n",
    "  model.compile(Adam(learning_rate = 0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdde73-085b-408e-a74b-96cfd1e831da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modified_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64725b-38bc-4201-8b49-0e49eead62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=50), steps_per_epoch=2000, epochs=10, validation_data=(X_val, y_val), shuffle = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d743a21-de30-4274-80ef-9bd3a5d2a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a12c9-e8d8-419b-8c08-b0c9e62bafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['training','test'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afad7e-a64d-490d-b071-0e9d596feebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48febaa-caeb-42f2-a516-39dea0e4e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict internet number\n",
    "import requests\n",
    "from PIL import Image\n",
    "url = 'https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg'\n",
    "r = requests.get(url, stream=True)\n",
    "img = Image.open(r.raw)\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "img = np.asarray(img)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = preprocess(img)\n",
    "plt.imshow(img, cmap = plt.get_cmap('gray'))\n",
    "print(img.shape)\n",
    "img = img.reshape(1, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779639b-ca09-48ab-aace-41315d6632b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted sign: \"+ str(model.predict_classes(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f02ba2-d6db-44d0-9d69-43263147d5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
